{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08cb5c06",
   "metadata": {},
   "source": [
    "# Haram Blur using Different Models and Approaches  \n",
    "> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daae5e6",
   "metadata": {},
   "source": [
    "### ✅ 1.(Detetctor = OpenCV) + (Gender Model =  Caffe Model)\n",
    "\n",
    "**OpenCV Haar est dépassé et moins précis, à éviter pour un projet sérieux**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13c532",
   "metadata": {},
   "source": [
    "#### 1.1 Try Model on Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4f59a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (185, 272, 3)\n",
      "Gender: Female with a confidence of 1.00\n",
      "Gender: Female with a confidence of 0.53\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Import Image to test model on \n",
    "img = cv2.imread('images.jpg')\n",
    "print(f\"Image Shape: {img.shape}\")\n",
    "# resize the image\n",
    "img = cv2.resize(img,(302,215))\n",
    "\n",
    "# Define the Classifier To detect the Faces and return => (x,y,w,h)\n",
    "cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "faces = cascade.detectMultiScale(img , 1.1 , 11)\n",
    "\n",
    "# Load the Model\n",
    "modelFile = \"gender_net.caffemodel\"\n",
    "configFile = \"gender_deploy.prototxt\"\n",
    "net = cv2.dnn.readNet(modelFile, configFile)\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    "for i,(x,y,w,h) in enumerate(faces):\n",
    "    roi = img[y-5:y+h+5 , x-5:x+w+5]\n",
    "\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    blob = cv2.dnn.blobFromImage(roi, 1, (227,227), (78.4263377603, 87.7689143744, 114.895847746))\n",
    "    net.setInput(blob)  \n",
    "    genderPreds = net.forward()\n",
    "    gender = genderList[genderPreds[0].argmax()]\n",
    "    confidence = f'{genderPreds[0].max():.2f}'\n",
    "    print(f'Gender: {gender} with a confidence of {confidence}')\n",
    "    if gender == 'Female':\n",
    "        img[y-5:y+h+5 , x-5:x+w+5] = cv2.GaussianBlur(roi,(99,99),33)\n",
    "    cv2.putText(img,gender,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,0,255),2,cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "\n",
    "cv2.imshow(\"boyand girl\",img)\n",
    "cv2.imwrite('HaramBlur.jpg',img)\n",
    "if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a2e86",
   "metadata": {},
   "source": [
    "#### 1.2 Try the model on Real Time Images From Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa8a16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "cap = cv2.VideoCapture(0)\n",
    "colors ={'pink':(255,0,255),'green' :(0,255,0) }\n",
    "\n",
    "while True:\n",
    "    # Capture the Frame to Pass to The model =>Detetct How Many Faces There\n",
    "    sucess , img = cap.read()\n",
    "    faces = cascade.detectMultiScale(img , 1.1 , 11)\n",
    "\n",
    "    # For Each Boundiing Box Detetcted => Run The Model\n",
    "    for (x,y,w,h) in faces:\n",
    "        # Get the ROI : Where the Face is Located AND Detetct it \n",
    "\n",
    "        roi = img[max(0,y-5):y+h+5 , max(0,x-5):x+w+5]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "\n",
    "        # Run The Model\n",
    "        blob = cv2.dnn.blobFromImage(roi, 1, (227,227), (78.4263377603, 87.7689143744, 114.895847746))\n",
    "        net.setInput(blob)  \n",
    "        genderPreds = net.forward()\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "        confidence = f'{genderPreds[0].max():.2f}'\n",
    "        message = f'Gender: {gender} with a confidence of {confidence}'\n",
    "        if gender == 'Female':\n",
    "            cvzone.putTextRect(img,message,(x,y-10),colorR=colors['pink'],colorB=(0,0,0),scale=1,thickness=2)\n",
    "            img[y-5:y+h+5 , x-5:x+w+5] = cv2.GaussianBlur(roi,(99,99),33)\n",
    "        else : \n",
    "            cvzone.putTextRect(img,message,(x,y-10),colorR=colors['green'],colorB=(0,0,0),scale=1,thickness=2)\n",
    "        \n",
    "    cv2.imshow(\"Gender Detection\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            cap.release()\n",
    "            break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697414f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01a8eacf",
   "metadata": {},
   "source": [
    "### ✅ 2.(Detetctor = Mediapipe) + (Gender Model =  Caffe Model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad074191",
   "metadata": {},
   "source": [
    "#### 2.1 Initailize The Lightweight model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "438382dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "modelFile = \"gender_net.caffemodel\"\n",
    "configFile = \"gender_deploy.prototxt\"\n",
    "net = cv2.dnn.readNet(modelFile, configFile)\n",
    "genderList = ['Male', 'Female']\n",
    "colors ={'pink':(255,0,255),'green' :(0,255,0) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "483a4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import cvzone\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image_rgb)\n",
    "\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                h, w, _ = image.shape\n",
    "                x = int(bbox.xmin * w)\n",
    "                y = int(bbox.ymin * h)\n",
    "                width = int(bbox.width * w)\n",
    "                height = int(bbox.height * h)\n",
    "\n",
    "                face = image[y:y+height, x:x+width]\n",
    "                # Detect if the face is a women or a Men \n",
    "                blob = cv2.dnn.blobFromImage(face,1,(227,227),(78.4263377603, 87.7689143744, 114.895847746))\n",
    "                net.setInput(blob)\n",
    "                genderPreds = net.forward()\n",
    "                gender = genderList[genderPreds[0].argmax()]\n",
    "\n",
    "\n",
    "                if gender == 'Female':\n",
    "                    image[y:y+height, x:x+width] = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "                    cv2.rectangle(image, (x, y), (x+width, y+height), color=colors[\"pink\"], thickness=2)\n",
    "                    cvzone.putTextRect(image,f'Gender: {gender}',(x,y-20),2,2,colorR=colors['pink'])\n",
    "                else :  \n",
    "                    cvzone.cornerRect(image,(x,y,width,height),colorR=colors['green'])\n",
    "                    cvzone.putTextRect(image,f'Gender: {gender}',(x,y-20),2,2,colorR=colors['green'])\n",
    "\n",
    "        cv2.imshow('Haram Blur', image)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
